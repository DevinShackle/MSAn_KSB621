---
title: "match1"
author: "Mara Johnson"
date: "11/29/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Prepare the R libraries**
```{R}
## This continues the code development that began on the AU campus
#  Identify the package to be used and open the respective libraries
options(scipen=999)

packages <- c("data.table"
              , "dplyr"
              , "GGally"
              , "ggplot2"
              , "Hmisc"
              , "knitr"
              , "reshape2"
            #  , "RODBC"
              , "scales"
              , "stringr")

for (package in packages) {
  message(sprintf("Checking that %s is installed...", package))
  if (!package %in% row.names(installed.packages())) {
    install.packages(package, repos = "https://cran.rstudio.com")
  }
}

library(data.table)
library(dplyr)
library(GGally)
library(ggplot2)
library(Hmisc)
library(knitr)
library(reshape2)
#library(RODBC)
library(scales)
library(stringr)

```

**Read the 100K data into a dataframe and reduce to MATCH = 1**

```{r}

## Get the 100K data from Dropbox
#PATH_TO_DATA = 'C:/Users/scott/Dropbox/MSAn Capstone - Fall 2017/Data/3. 100K Sampled Data/FINAL2_SAMPLED100.csv' #Scott's Path
PATH_TO_DATA <- "~/Dropbox/MSAn Capstone - Fall 2017/Data/3. 100K Sampled Data/FINAL2_SAMPLED100.csv" #Devin's Path

## Form the total data frame
df <- read.csv(PATH_TO_DATA)

## Remove objects that are no longer needed
rm(package)
rm(packages)
#rm(PATH_TO_DATA)

## Split the data into two pieces; this will keep only the non-matched data
df.m1 <- df[df$MATCH==1,]

##Remove 3rd party variables
df.m1 <- select(df.m1, c("RESP","individual_id","days_since_last_activity","Upmarket"))

```

## Compute interaction variables

```{r}

df.m1$days_squared <- df.m1$days_since_last_activity**2
df.m1$days_PROD_Up <- df.m1$days_since_last_activity * df.m1$Upmarket
df.m1$days_PROD_UpPlusOne <- df.m1$days_since_last_activity * (df.m1$Upmarket + 1)
df.m1$days_squared_PROD_Up <- df.m1$days_squared * df.m1$Upmarket
df.m1$days_log <- log(df.m1$days_since_last_activity)
df.m1$log_days_PROD_UpPlusOne <- log(df.m1$days_PROD_UpPlusOne)

# We will also try standardizing both the days_since and log(days_since) variables
df.m1$days_stand <- df.m1$days_since_last_activity
df.m1$days_log_stand <- df.m1$days_log
df.m1$days_PROD_UpPlusOne_stand <- df.m1$days_PROD_UpPlusOne

df.m1 <- df.m1 %>% mutate_each_(funs(scale(.) %>% as.vector), vars=c("days_stand","days_log_stand","days_PROD_UpPlusOne_stand"))



```


## Split into training and test sets

```{r}

set.seed(1)

train <- sample(1:nrow(df.m1), nrow(df.m1)*0.8) 
test <- (-train)


```


## Logistic Regression


```{r}


# # Null model with only the intercept (specifying the number 1 as a predictor fits a model with just the intercept and no other predictors)
m1.null <- glm(RESP~1,data=df.m1,subset = train, family=binomial(link="logit"))

# # Full mode with ALL the variables
m1.full <- glm(RESP~.,data=df.m1,subset = train, family=binomial(link="logit"))

summary(m1.null)
summary(m1.full)


m1.stepwise <- step(m1.null, scope=list(lower=m1.null, upper=m1.full), direction = "both", test="Chisq")
summary(m1.stepwise)



```

```{r}

# This function will evaluate a confusion matrix and give a plain-language description of it's impact on both retention of business value and reduction in email volume

evaluateTable <- function(t) {
  if(class(t) == "table" & length(dim(t)) == 2 & dim(t)[1] == 2 & dim(t)[2] == 2) {
    trueNegatives <- t[1,1]
    falseNegatives <- t[1,2]
    falsePositives <- t[2,1]
    truePositives <- t[2,2]
    totalEmails <- trueNegatives + falseNegatives + falsePositives + truePositives
    maxResp <- falseNegatives + truePositives
    businessValue <- percent(truePositives / maxResp)
    emailVolumeReductionPotential <- percent((trueNegatives + falseNegatives) / totalEmails)
    paste("Retains", businessValue, "of business value and reduces email volume by", emailVolumeReductionPotential, sep = " ")
  }
}

```



```{r}
## Model with the best 3 variables
m1.train.best3 <- glm(RESP~days_log+Upmarket+days_PROD_UpPlusOne, data=df.m1, subset = train,family=binomial(link="logit"))
summary(m1.train.best3)

#use model to predict response in training set
m1.train.best3.probs <- predict(m1.train.best3,type="response")

# cuttoff probability of 0.1
m1.train.best3.pred <- ifelse(m1.train.best3.probs>0.1, 1, 0)
conf.mat <- table(m1.train.best3.pred,df.m1$RESP[train]) 
conf.mat
evaluateTable(conf.mat)

# cuttoff probability of 0.06
m1.train.best3.pred <- ifelse(m1.train.best3.probs>0.06, 1, 0)
conf.mat <- table(m1.train.best3.pred,df.m1$RESP[train]) 
conf.mat
evaluateTable(conf.mat)

# cuttoff probability of 0.035
m1.train.best3.pred <- ifelse(m1.train.best3.probs>0.035, 1, 0)
conf.mat <- table(m1.train.best3.pred,df.m1$RESP[train]) 
conf.mat
evaluateTable(conf.mat)

```


```{r}
# model with the best 2 variables
m1.train.best2 <- glm(RESP~days_log+Upmarket, data=df.m1, subset = train,family=binomial(link="logit"))
summary(m1.train.best2)

#use model to predict response in training set
m1.train.best2.probs <- predict(m1.train.best2,type="response")

# cuttoff probability of 0.1
m1.train.best2.pred <- ifelse(m1.train.best2.probs>0.1, 1, 0)
conf.mat <- table(m1.train.best2.pred,df.m1$RESP[train]) 
conf.mat
evaluateTable(conf.mat)

# cuttoff probability of 0.06
m1.train.best2.pred <- ifelse(m1.train.best2.probs>0.06, 1, 0)
conf.mat <- table(m1.train.best2.pred,df.m1$RESP[train]) 
conf.mat
evaluateTable(conf.mat)

# cuttoff probability of 0.035
m1.train.best2.pred <- ifelse(m1.train.best2.probs>0.035, 1, 0)
conf.mat <- table(m1.train.best2.pred,df.m1$RESP[train]) 
conf.mat
evaluateTable(conf.mat)

```

```{r}
#model with the best variable

m1.train.best1 <- glm(RESP~days_PROD_UpPlusOne, data=df.m1, subset = train,family=binomial(link="logit"))
summary(m1.train.best1)

#use model to predict response in training set
m1.train.best1.probs <- predict(m1.train.best1,type="response")

# cuttoff probability of 0.1
m1.train.best1.pred <- ifelse(m1.train.best1.probs>0.1, 1, 0)
conf.mat <- table(m1.train.best1.pred,df.m1$RESP[train]) 
conf.mat
evaluateTable(conf.mat)

# cuttoff probability of 0.06
m1.train.best1.pred <- ifelse(m1.train.best1.probs>0.06, 1, 0)
conf.mat <- table(m1.train.best1.pred,df.m1$RESP[train]) 
conf.mat
evaluateTable(conf.mat)

# cuttoff probability of 0.035
m1.train.best1.pred <- ifelse(m1.train.best1.probs>0.035, 1, 0)
conf.mat <- table(m1.train.best1.pred,df.m1$RESP[train]) 
conf.mat
evaluateTable(conf.mat)

```




```{r}
# # for evaluating against the test data
# m1.test.probs <- predict(m1.train.best, newdata = df.m1,type="response")[test]
# m1.test.pred <- ifelse(m1.test.probs>0.1, 1, 0)
# conf.mat <- table(m1.test.pred,df.m1$RESP[test]) 
# conf.mat

```